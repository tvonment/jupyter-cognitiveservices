{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/python/latest/bin/python -m pip install --upgrade pip\n",
    "!/opt/python/latest/bin/python -m pip install matplotlib\n",
    "!/opt/python/latest/bin/python -m pip install requests\n",
    "!/opt/python/latest/bin/python -m pip install json\n",
    "!/opt/python/latest/bin/python -m pip install IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import IPython\n",
    "\n",
    "from matplotlib import patches\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from pprint import pprint\n",
    "from xml.etree import ElementTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your Cognitive Services subscription key and endpoint\n",
    "subscription_key = '<<key>>'\n",
    "endpoint = 'https://cogservthomas.cognitiveservices.azure.com/'\n",
    "imagecontainerlink = 'https://raw.githubusercontent.com/tvonment/jupyter-cognitiveservices/main/images/'\n",
    "region = \"switzerlandnorth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer Vision\n",
    "\n",
    "analyze_url = endpoint + \"vision/v2.1/analyze\"\n",
    "#(https://westcentralus.dev.cognitive.microsoft.com/docs/services/5adf991815e1060e6355ad44/operations/56f91f2e778daf14a499e1fa)\n",
    "\n",
    "\n",
    "# Set image_url to the URL of an image that you want to analyze.\n",
    "image_url = imagecontainerlink + \"stadion.jpg\"\n",
    "#image_url = imagecontainerlink + \"handofthequeen.png\"\n",
    "#image_url = imagecontainerlink + \"ms_shirt.jpg\"\n",
    "\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "params = {'visualFeatures': 'Categories,Description,Color'}\n",
    "#params = {'visualFeatures': 'Brands,Description,Color'}\n",
    "\n",
    "data = {'url': image_url}\n",
    "response = requests.post(analyze_url, headers=headers,\n",
    "                         params=params, json=data)\n",
    "response.raise_for_status()\n",
    "\n",
    "# The 'analysis' object contains various fields that describe the image. The most\n",
    "# relevant caption for the image is obtained from the 'description' property.\n",
    "analysis = response.json()\n",
    "\n",
    "#print(json.dumps(response.json(), indent=2))\n",
    "image_caption = analysis[\"description\"][\"captions\"][0][\"text\"].capitalize()\n",
    "\n",
    "# Display the image and overlay it with the caption.\n",
    "image = Image.open(BytesIO(requests.get(image_url).content))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "_ = plt.title(image_caption, size=\"x-large\", y=-0.1)\n",
    "plt.show()\n",
    "\n",
    "pprint(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Analytics\n",
    "## Language\n",
    "\n",
    "language_api_url = endpoint + \"text/analytics/v2.0/languages\"\n",
    "\n",
    "documents = { 'documents': [\n",
    "    { 'id': '1', 'text': 'This is a document written in English.' },\n",
    "    { 'id': '2', 'text': 'Este es un document escrito en Español.' },\n",
    "    { 'id': '3', 'text': '这是一个用中文写的文件' }\n",
    "]}\n",
    "\n",
    "headers   = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "response  = requests.post(language_api_url, headers=headers, json=documents)\n",
    "languages = response.json()\n",
    "pprint(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Analytics\n",
    "## Sentiment\n",
    "\n",
    "sentiment_api_url = endpoint + \"text/analytics/v2.0/sentiment\"\n",
    "\n",
    "documents = {'documents' : [\n",
    "  {'id': '1', 'language': 'en', 'text': 'I had a wonderful experience! The rooms were wonderful and the staff was helpful.'},\n",
    "  {'id': '2', 'language': 'en', 'text': 'I had a terrible time at the hotel. The staff was rude and the food was awful.'},  \n",
    "  {'id': '3', 'language': 'es', 'text': 'Los caminos que llevan hasta Monte Rainier son espectaculares y hermosos.'},  \n",
    "  {'id': '4', 'language': 'de', 'text': 'Ich bin nicht sicher ob das ein gutes Auto ist?'}\n",
    "]}\n",
    "\n",
    "headers   = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "response  = requests.post(sentiment_api_url, headers=headers, json=documents)\n",
    "sentiments = response.json()\n",
    "pprint(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Analytics\n",
    "## Key Phrases\n",
    "\n",
    "key_phrase_api_url = endpoint + \"text/analytics/v2.0/keyPhrases\"\n",
    "headers   = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "\n",
    "response  = requests.post(key_phrase_api_url, headers=headers, json=documents)\n",
    "key_phrases = response.json()\n",
    "pprint(key_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech\n",
    "\n",
    "# Download the audio file\n",
    "!curl https://raw.githubusercontent.com/MicrosoftLearning/AI-Introduction/master/files/RainSpain.wav -o RainSpain.wav\n",
    "    \n",
    "# Play the audio\n",
    "IPython.display.Audio('RainSpain.wav', autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech to Text\n",
    "with open(\"RainSpain.wav\", mode=\"rb\") as audio_file:\n",
    "        audio_data =  audio_file.read()\n",
    "        \n",
    "# The Speech API requires an access token (valid for 10 mins)\n",
    "apiEndPoint = \"https://\" + region + \".api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "\n",
    "# Use the API key to request an access token\n",
    "response = requests.post(apiEndPoint, headers=headers)\n",
    "accesstoken = str(response.text)\n",
    "\n",
    "# Now that we have a token, we can set up the request\n",
    "speechToTextEndPoint = \"https://\" + region + \".stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1\"\n",
    "headers = {\"Content-type\": \"audio/wav; codec=audio/pcm; samplerate=16000\", \n",
    "           \"Authorization\": \"Bearer \" + accesstoken}\n",
    "params = {\"language\":\"en-US\"}\n",
    "body = audio_data\n",
    "\n",
    "# Connect to server, post the request, and get the result\n",
    "response = requests.post(speechToTextEndPoint,data=body, params=params, headers=headers)\n",
    "result = str(response.text)\n",
    "print(json.loads(result)['DisplayText'])\n",
    "\n",
    "pprint(json.loads(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text to Speech\n",
    "# Get the input text\n",
    "\n",
    "myText = input('What would you like me to say?: \\n')\n",
    "        \n",
    "# The Speech API requires an access token (valid for 10 mins)\n",
    "apiEndPoint = \"https://\" + region + \".api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "\n",
    "# Use the API key to request an access token\n",
    "response = requests.post(apiEndPoint, headers=headers)\n",
    "accesstoken = str(response.text)\n",
    "\n",
    "# Now that we have a token, we can set up the request\n",
    "textToSpeechEndPoint = \"https://\" + region + \".tts.speech.microsoft.com/cognitiveservices/v1\"\n",
    "headers = {\"Content-type\": \"application/ssml+xml\",\n",
    "           'X-Microsoft-OutputFormat': 'riff-16khz-16bit-mono-pcm',\n",
    "           'User-Agent': 'speech',\n",
    "           \"Authorization\": \"Bearer \" + accesstoken}\n",
    "\n",
    "# The request body is XML\n",
    "body = \"<speak version='1.0' xml:lang='en-US'>\\\n",
    "          <voice xml:lang='en-US'\\\n",
    "                 xml:gender='Female'\\\n",
    "                 name='Microsoft Server Speech Text to Speech Voice (en-US, ZiraRUS)'>\" + myText + \"</voice>\\\n",
    "        </speak>\"\n",
    "\n",
    "\n",
    "# Connect to server, post the request, and get the result\n",
    "response = requests.post(textToSpeechEndPoint,data=body, headers=headers)\n",
    "\n",
    "#Play the audio\n",
    "IPython.display.Audio(response.content, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face API\n",
    "\n",
    "face_api_url = endpoint + 'face/v1.0/detect'\n",
    "image_url = 'https://how-old.net/Images/faces2/main007.jpg'\n",
    "\n",
    "headers = { 'Ocp-Apim-Subscription-Key': subscription_key }\n",
    "    \n",
    "params = {\n",
    "    'returnFaceId': 'true',\n",
    "    'returnFaceLandmarks': 'false',\n",
    "    'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise',\n",
    "}\n",
    "\n",
    "response = requests.post(face_api_url, params=params, headers=headers, json={\"url\": image_url})\n",
    "faces = response.json()\n",
    "print(\"detected \" + str(len(faces)) + \" faces\")\n",
    "image = Image.open(BytesIO(requests.get(image_url).content))\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "pprint(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image(image_url):\n",
    "    response = requests.post(face_api_url, params=params, headers=headers, json={\"url\": image_url})\n",
    "    faces = response.json()\n",
    "\n",
    "    image_file = BytesIO(requests.get(image_url).content)\n",
    "    image = Image.open(image_file)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = plt.imshow(image, alpha=0.6)\n",
    "    for face in faces:\n",
    "        fr = face[\"faceRectangle\"]\n",
    "        fa = face[\"faceAttributes\"]\n",
    "        origin = (fr[\"left\"], fr[\"top\"])\n",
    "        p = patches.Rectangle(origin, fr[\"width\"], \\\n",
    "                              fr[\"height\"], fill=False, linewidth=2, color='b')\n",
    "        ax.axes.add_patch(p)\n",
    "        plt.text(origin[0], origin[1], \"%s, %d\"%(fa[\"gender\"].capitalize(), fa[\"age\"]), \\\n",
    "                 fontsize=20, weight=\"bold\", va=\"bottom\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_image(\"https://how-old.net/Images/faces2/main001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_image(\"https://how-old.net/Images/faces2/main002.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotate_image(\"https://how-old.net/Images/faces2/main004.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.3 64-bit",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d9af2e32a5ad6e5c5f98229481d7f4ca3d60c1f6ad52fd9ba4da285d14500705"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}